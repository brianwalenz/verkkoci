import tempfile
import os
import re
import glob
import time
import math

SCRIPT_PATH=config['SCRIPT_PATH']
ROOT_PATH=config['ROOT_PATH']
HIFI_READS=glob.glob(os.path.expandvars(config['HIFI_READS']))
print("HiFi reads", HIFI_READS)
ONT_READS=glob.glob(os.path.expandvars(config['ONT_READS']))
print("ONT reads", ONT_READS)

localrules: all

rule all:
    input:
        'unitig-popped-unitig-normal-connected-tip.gfa',
        'hificov-unitig-popped-unitig-normal-connected-tip.csv',
        'ontcov-unitig-popped-unitig-normal-connected-tip.csv',
        'concat.fa'

rule build_graph:
    input:
        HIFI_READS
    output:
        gfa='hifi-resolved.gfa',
        paths='paths.gaf'
    threads: 8
    log:
        'graph_building.log'
    params:
        input_str=' '.join(expand('-i {r}', r=HIFI_READS)),
        baseK=config['MIN_KMER'],
        w=100,
        maxK=15000
    shell:
        '''
        /usr/bin/time -v MBG {params.input_str} -t {threads} -o {output.gfa} -k {params.baseK} -w {params.w} -a 1 -u 2 --error-masking=collapse-msat --output-sequence-paths {output.paths} -r {params.maxK} &> {log}
        '''

rule hifi_coverage_csv:
  input:
    "hifi-resolved.gfa"
  output:
    "hifi_nodecov.csv"
  shell:
    '''
    awk 'BEGIN{{print "node\\tlength\\tcoverage";}}$1=="S"{{if ($6 != "") {{$4 = $6;}} print $2 "\\t" length($3) "\\t" substr($4, 6);}}' < {input} > {output}
    '''

rule process_graph:
    input:
        gfa='hifi-resolved.gfa',
        paths='paths.gaf'
    output:
        processed_gfa='unitig-unrolled-hifi-resolved.gfa'
    shell:
        '''
        {SCRIPT_PATH}/insert_aln_gaps.py {input.gfa} 2 50 gaps-hifi-1.gaf gapone < {input.paths} > gapped-once-hifi-resolved.gfa
        {SCRIPT_PATH}/insert_aln_gaps.py gapped-once-hifi-resolved.gfa 2 300 gaps-hifi-2.gaf gaptwo < {input.paths} > gapped-twice-hifi-resolved.gfa
        {SCRIPT_PATH}/insert_aln_gaps.py gapped-twice-hifi-resolved.gfa 1 5 gaps-hifi-3.gaf gapthree < {input.paths} > gapped-hifi-resolved.gfa
        cut -f 6 < {input.paths} | {SCRIPT_PATH}/unroll_tip_loops.py gapped-hifi-resolved.gfa 5 > unrolled-hifi-resolved.gfa
        {SCRIPT_PATH}/get_unroll_mapping.py gapped-hifi-resolved.gfa unrolled-hifi-resolved.gfa > unroll_mapping_1.txt
        {SCRIPT_PATH}/unitigify.py "utig1-" unitig-mapping-1.txt < unrolled-hifi-resolved.gfa > {output.processed_gfa}
        '''

rule align_ont:
    input: reads=lambda wildcards: ONT_READS[int(wildcards.i)],
           graph='unitig-unrolled-hifi-resolved.gfa'
    output: 'ont_align/read_file{i}.gaf'
    threads: 32
    log: 'ont_align/read_file{i}.log'
    shell:
        '''
        /usr/bin/time -v GraphAligner -t {threads} -g {input.graph} -f {input.reads} -a {output} -x vg --seeds-minimizer-density 0.1 -b 15 --multimap-score-fraction 0.99 --precise-clipping 0.85 --min-alignment-score 5000 --hpc-collapse-reads --discard-cigar --clip-ambiguous-ends 100 --overlap-incompatible-cutoff 0.15 --max-trace-count 5 &> {log}
        '''

rule aggregate:
    input: expand('ont_align/read_file{i}.gaf', i=range(0, len(ONT_READS)))
    output: 'alns-ont.gaf'
    shell: 'cat {input} > alns-ont.gaf'

rule process_ont_paths:
#unitig-unrolled-hifi-resolved.gfa alns-ont.gaf unitig-unrolled-ont-resolved.gfa 5 20 10 5
    input: graph='unitig-unrolled-hifi-resolved.gfa',
           ont_paths='alns-ont.gaf',
           hifi_coverage="hifi_nodecov.csv"
    output: graph='unitig-unrolled-ont-resolved.gfa',
            #TODO pass as parameter?
            ont_gap_align='gaps-ont.gaf',
            ont_covs="nodecovs-ont.csv"
    log: 'process_ont_paths.log'
    params:
        #TODO remove default values, must be in config or passed via command line!
        min_allowed_cov=config.get('ONT_COV_THR', 5),
        resolve_steps=config.get('ONT_RESOLVE_STEPS', '20 10 5')
    shell:
        '''
        {ROOT_PATH}/process_ont_paths.sh {input.graph} {input.ont_paths} {output.graph} {params.min_allowed_cov} {params.resolve_steps} &> {log}
        '''

rule postprocess:
    input:
        graph='unitig-unrolled-ont-resolved.gfa',
        hifi_coverage="hifi_nodecov.csv"
    output: 'unitig-popped-unitig-normal-connected-tip.gfa'
    log: 'postprocess.log'
    shell:
        '''
        {ROOT_PATH}/postprocess.sh {input.graph} {output} &> {log}
        '''

rule create_final_coverages:
    input:
        graph="unitig-popped-unitig-normal-connected-tip.gfa",
        hifi_coverage="hifi_nodecov.csv",
        ont_coverage="nodecovs-ont.csv"
    output:
        hifi_coverage="hificov-unitig-popped-unitig-normal-connected-tip.csv",
        ont_coverage="ontcov-unitig-popped-unitig-normal-connected-tip.csv"
    shell:
        '''
        cat *mapping* > combined-nodemap-final.txt
        rm -f combined-edges-final.gfa
        cat hifi-resolved.gfa gapped-once-hifi-resolved.gfa gapped-twice-hifi-resolved.gfa gapped-hifi-resolved.gfa unrolled-hifi-resolved.gfa unitig-unrolled-hifi-resolved.gfa gapped-unitig-unrolled-hifi-resolved.gfa connected.gfa normal-connected.gfa ont-resolved-graph.gfa unrolled-ont-resolved.gfa unitig-unrolled-ont-resolved.gfa connected-tip.gfa unitig-normal-connected-tip.gfa popped-unitig-normal-connected-tip.gfa unitig-popped-unitig-normal-connected-tip.gfa | grep -P '^L' > combined-edges-final.gfa
        grep -P '^S' hifi-resolved.gfa gapped-once-hifi-resolved.gfa gapped-twice-hifi-resolved.gfa gapped-hifi-resolved.gfa unrolled-hifi-resolved.gfa unitig-unrolled-hifi-resolved.gfa gapped-unitig-unrolled-hifi-resolved.gfa connected.gfa normal-connected.gfa ont-resolved-graph.gfa unrolled-ont-resolved.gfa unitig-unrolled-ont-resolved.gfa connected-tip.gfa unitig-normal-connected-tip.gfa popped-unitig-normal-connected-tip.gfa unitig-popped-unitig-normal-connected-tip.gfa | grep -v '\\*' | awk '{{print $2 "\\t" length($3);}}' > nodelens-final.txt
        {SCRIPT_PATH}/get_original_coverage.py {input.graph} combined-nodemap-final.txt combined-edges-final.gfa nodelens-final.txt {input.hifi_coverage} > {output.hifi_coverage}
        {SCRIPT_PATH}/get_original_coverage.py {input.graph} combined-nodemap-final.txt combined-edges-final.gfa nodelens-final.txt {input.ont_coverage} > {output.ont_coverage}
        '''

rule create_layout:
    input: graph='unitig-popped-unitig-normal-connected-tip.gfa',
           paths='paths.gaf'
    output:
        #combined_edges=temp('combined-edges.gfa'),
        layout='layout.txt',
        gaps='gaps.txt'
    threads: 1
    shell:
        '''
        cat *mapping* > combined-nodemap.txt
        rm -f combined-edges.gfa
        cat *.gfa | grep -P '^L' > combined-edges.gfa
        cat gaps-*.gaf {input.paths} > combined-alignments.gaf
        grep -P '^S' *.gfa | grep -v '\\*' | awk '{{print $2 "\\t" length($3);}}' > nodelens.txt
        grep -P '^S' {input.graph} | awk '{{print $2 "\\t" ">" $2;}}' > consensus_paths.txt
        {SCRIPT_PATH}/get_layout_from_mbg.py combined-nodemap.txt combined-edges.gfa combined-alignments.gaf consensus_paths.txt nodelens.txt > {output.layout} 2> unitig_to_mbg_list.txt
        {SCRIPT_PATH}/check_layout_gaps.py < {output.layout} > {output.gaps}
        '''

rule get_ont_subset:
   input: ont=ONT_READS,
          ont_gap_align='gaps-ont.gaf'
   output:
          ont_subset='ont_subset.faq'
   shell:
      '''
      rm -f {output.ont_subset}
      cat {input.ont_gap_align} |cut -f 1 |sort |uniq > used_ont.txt
      for o in {input.ont}; do seqtk subseq $o used_ont.txt >> {output.ont_subset}; done
      '''

checkpoint partition_consensus:
   input: layout='layout.txt',
          hifi=HIFI_READS,
          ont_subset='ont_subset.faq'
   output:
          cns=directory("ctgStore")
   log: 'partition.err'
   shell:
      '''
      mkdir -p {output.cns}
      layoutToPackage -layout {input.layout} -output {output.cns}/part.####.cnspack -idmap {output.cns}/part -partition 0.8 1.5 0.1 -reads {input.ont_subset} {input.hifi} &> {log}
      '''

def get_cns_inputs(wildcards):
   out = checkpoints.partition_consensus.get().output[0]
   return [s.replace('.cnspack', '') for s in glob.glob(out + "/*.cnspack")]

rule cns:
    input: '{partition}.cnspack'
    output: 
           cns='{partition}.fa',
    threads: 32
    log: '{partition}.log'
    shell:
        '''
        utgcns -V -V -V -threads {threads} -import {input} -A {output.cns} -maxcoverage 50 -e 0.20 -l 2500 -pbdagcon -edlib &> {log}
        '''

rule aggregate_cns:
   input: lambda wildcards: expand('{partition}.fa', partition=get_cns_inputs(wildcards))
   output: 'concat.fa'
   shell: 'cat {input} | {SCRIPT_PATH}/rename_reads.py - ctgStore/part.tigName_to_ID.map {output}'
